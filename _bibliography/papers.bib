---
---


@inproceedings{Bressa2024,
  bibtex_show={true},
  author = {Bressa, Nathalie and Louis, Jordan and Willett, Wesley and Huron, Samuel},
  title = {Input Visualization: Collecting and Modifying Data with Visual Representations},
  year = {2024},
  isbn = {9798400703300},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3613904.3642808},
  doi = {10.1145/3613904.3642808},
  abstract = {We examine input visualizations, visual representations that are designed to collect (and represent) new data rather than encode preexisting datasets. Information visualization is commonly used to reveal insights and stories within existing data. As a result, most contemporary visualization approaches assume existing datasets as the starting point for design, through which that data is mapped to visual encodings. Meanwhile, the implications of visualizations as inputs and as data sources have received little attention—despite the existence of visual and physical examples stretching back centuries. In this paper, we present a design space of 50 input visualizations analyzing their visual representation, data, artifact, context, and input. Based on this, we identify input modalities, purposes of input visualizations, and a set of design considerations. Finally, we discuss the relationship between input visualization and traditional visualization design and suggest opportunities for future research to better understand these visual representations and their potential.},
  booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  articleno = {499},
  numpages = {18},
  keywords = {data collection, data discussion, input visualization, interaction, participation, physicalization, public engagement, survey, visualization},
  location = {Honolulu, HI, USA},
  video={https://www.youtube-nocookie.com/embed/wilUZ5wbTiw},
  preview={2024-chi-table1.png},
  selected={true},
  series = {CHI '24},
  pdf={https://osf.io/c9j8s},
  url={https://osf.io/bw3gp/?view_only=}
}

@inproceedings{Bonnail2024,
  bibtex_show={true},
  selected={true},
  author = {Bonnail, Elise and Frommel, Julian and Lecolinet, Eric and Huron, Samuel and Gugenheimer, Jan},
  title = {Was it Real or Virtual? Confirming the Occurrence and Explaining Causes of Memory Source Confusion between Reality and Virtual Reality},
  year = {2024},
  isbn = {9798400703300},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3613904.3641992},
  doi = {10.1145/3613904.3641992},
  abstract = {Source confusion occurs when individuals attribute a memory to the wrong source (e.g., confusing a picture with an experienced event). Virtual Reality (VR) represents a new source of memories particularly prone to being confused with reality. While previous research identified causes of source confusion between reality and other sources (e.g., imagination, pictures), there is currently no understanding of what characteristics specific to VR (e.g., immersion, presence) could influence source confusion. Through a laboratory study (n=29), we 1) confirm the existence of VR source confusion with current technology, and 2) present a quantitative and qualitative exploration of factors influencing VR source confusion. Building on the Source Monitoring Framework, we identify VR characteristics and assumptions about VR capabilities (e.g., poor rendering) that are used to distinguish virtual from real memories. From these insights, we reflect on how the increasing realism of VR could leave users vulnerable to memory errors and perceptual manipulations.},
  booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
  articleno = {796},
  numpages = {17},
  keywords = {Memory, Source Confusion, Source Misattribution, Virtual Reality},
  location = {Honolulu, HI, USA},
  video={https://www.youtube-nocookie.com/embed/NagIRCvq-Eo},
  preview={2024-source-confusion.jpg},
  series = {CHI '24}
}

@INPROCEEDINGS{Tseng2024,
  bibtex_show={true},
  author={Tseng, Wen-Jie and Kontrazis, Petros Dimitrios and Lecolinet, Eric and Huron, Samuel and Gugenheimer, Jan},
  booktitle={2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR)}, 
  title={Understanding Interaction and Breakouts of Safety Boundaries in Virtual Reality Through Mixed-Method Studies}, 
  year={2024},
  volume={},
  number={},
  pages={482-492},
  keywords={Surveys;Three-dimensional displays;Virtual reality;User interfaces;Aerospace electronics;Encoding;Safety;Human-centered computing;Human computer interaction (HCI);Interaction paradigms;Virtual reality;Empirical studies in HCI},
  doi={10.1109/VR58804.2024.00069},
  preview={2024-Breakouts-of-Safety-Boundaries.png}
}

@INPROCEEDINGS {Wei2023,
  bibtex_show={true},
  author = {W. Wei and S. Huron and Y. Jansen},
  booktitle = {2023 IEEE Visualization and Visual Analytics (VIS)},
  title = {Towards Autocomplete Strategies for Visualization Construction},
  year = {2023},
  volume = {},
  issn = {},
  pages = {141-145},
  abstract = {Constructive visualization uses physical data units - tokens - to enable non-experts to create personalized visualizations engagingly. However, its physical nature limits efficiency and scalability. One potential solution to address this issue is autocomplete. By providing automated suggestions while still allowing for manual intervention, autocomplete can expedite visualization construction while maintaining expressivity. We conduct a speculative design study to examine how people would like to interact with a visualization authoring system that supports autocomplete. Our study identifies three types of autocomplete strategies and gains insights for designing future visualization authoring tools with autocomplete functionality.A free copy of this paper and all supplemental materials are available on our online repository: https://osf.io/nu4z3/?view_only&#x3D; 594baee54d114a99ab381886fb32a126.},
  keywords = {authoring systems;visual analytics;scalability;data visualization;manuals;rendering (computer graphics)},
  doi = {10.1109/VIS54172.2023.00037},
  url = {https://doi.ieeecomputersociety.org/10.1109/VIS54172.2023.00037},
  publisher = {IEEE Computer Society},
  address = {Los Alamitos, CA, USA},
  preview = {2023-autocomplete.png},
  pdf = {https://arxiv.org/abs/2308.02679},
  month = {oct}
}


@inproceedings{Bonnail2023,
  bibtex_show={true},
  author = {Bonnail, Elise and Tseng, Wen-Jie and Mcgill, Mark and Lecolinet, Eric and Huron, Samuel and Gugenheimer, Jan},
  title = {Memory Manipulations in Extended Reality},
  year = {2023},
  isbn = {9781450394215},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3544548.3580988},
  doi = {10.1145/3544548.3580988},
  abstract = {Human memory has notable limitations (e.g., forgetting) which have necessitated a variety of memory aids (e.g., calendars). As we grow closer to mass adoption of everyday Extended Reality (XR), which is frequently leveraging perceptual limitations (e.g., redirected walking), it becomes pertinent to consider how XR could leverage memory limitations (forgetting, distorting, persistence) to induce memory manipulations. As memories highly impact our self-perception, social interactions, and behaviors, there is a pressing need to understand XR Memory Manipulations (XRMMs). We ran three speculative design workshops (n=12), with XR and memory researchers creating 48 XRMM scenarios. Through thematic analysis, we define XRMMs, present a framework of their core components and reveal three classes (at encoding, pre-retrieval, at retrieval). Each class differs in terms of technology (AR, VR) and impact on memory (influencing quality of memories, inducing forgetting, distorting memories). We raise ethical concerns and discuss opportunities of perceptual and memory manipulations in XR.},
  booktitle = {Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems},
  articleno = {875},
  numpages = {20},
  keywords = {Augmented Reality, Extended Reality, Perceptual Manipulations, Speculative Design, Virtual Reality, XR Memory Manipulations},
  location = {Hamburg, Germany},
  annotation = {* This paper received an Honorable Mention Award},
  preview = {2023-Memory-manipulation.png},
  video = {https://www.youtube-nocookie.com/embed/iGIdRoINgsw},
  pdf = {https://hal.science/I3-TPT/hal-04058016v1},
  selected={true},
  series = {CHI '23}
}

@article{bach2023challenges,
  bibtex_show={true},
  author = {B. Bach and M. Keck and F. Rajabiyazdi and T. Losev and I. Meirelles and J. Dykes and R. S. Laramee and M. AlKadi and C. Stoiber and S. Huron and C. Perin and L. Morais and W. Aigner and D. Kosminsky and M. Boucher and S. Knudsen and A. Manataki and J. Aerts and U. Hinrichs and J. C. Roberts and S. Carpendale},
  journal = {IEEE Transactions on Visualization &amp; Computer Graphics},
  title = {Challenges and Opportunities in Data Visualization Education: A Call to Action},
  year = {2024},
  volume = {30},
  number = {01},
  issn = {1941-0506},
  pages = {649-660},
  abstract = {This paper is a call to action for research and discussion on data visualization education. As visualization evolves and spreads through our professional and personal lives, we need to understand how to support and empower a broad and diverse community of learners in visualization. Data Visualization is a diverse and dynamic discipline that combines knowledge from different fields, is tailored to suit diverse audiences and contexts, and frequently incorporates tacit knowledge. This complex nature leads to a series of interrelated challenges for data visualization education. Driven by a lack of consolidated knowledge, overview, and orientation for visualization education, the 21 authors of this paper—educators and researchers in data visualization—identify and describe 19 challenges informed by our collective practical experience. We organize these challenges around seven themes People, Goals &amp; Assessment, Environment, Motivation, Methods, Materials, and Change. Across these themes, we formulate 43 research questions to address these challenges. As part of our call to action, we then conclude with 5 cross-cutting opportunities and respective action items: embrace DIVERSITY+INCLUSION, build COMMUNITIES, conduct RESEARCH, act AGILE, and relish RESPONSIBILITY. We aim to inspire researchers, educators and learners to drive visualization education forward and discuss why, how, who and where we educate, as we learn to use visualization to address challenges across many scales and many domains in a rapidly changing world: viseducationchallenges.github.io.},
  keywords = {data visualization;education;visualization;seminars;art;cultural differences;creativity},
  doi = {10.1109/TVCG.2023.3327378},
  publisher = {IEEE Computer Society},
  address = {Los Alamitos, CA, USA},
  preview = {2023-Visualization-Education.png},
  video = {https://www.youtube-nocookie.com/embed/MtsLr5b9pDM},
  pdf = {https://arxiv.org/abs/2308.07703},
  month = {jan}
}


@book{huron2022making,
  bibtex_show = {true},
  title = {Making with Data: Physical Design and Craft in a Data-Driven World},
  author = {Huron, Samuel and Nagel, Till and Oehlberg, Lora and Willett, Wesley},
  year = {2022},
  publisher = {CRC Press},
  preview = {2022-MKWD.jpg},
  abstract = {Making with Data: Physical Design and Craft in a Data-Driven World provides a snapshot of the diverse practices contemporary creators are using to produce objects, spaces, and experiences imbued with data. Across 25+ beautifully-illustrated chapters, international artists, designers, and scientists each explain the process of creating a specific data-driven piece—illustrating their practice with candid sketches, photos, and design artifacts from their own studios.},
  website = {https://makingwithdata.org/}
}

@inproceedings{Tseng2022,
  bibtex_show = {true},
  selected={true},
  author = {Tseng, Wen-Jie and Bonnail, Elise and McGill, Mark and Khamis, Mohamed and Lecolinet, Eric and Huron, Samuel and Gugenheimer, Jan},
  title = {The Dark Side of Perceptual Manipulations in Virtual Reality},
  year = {2022},
  isbn = {9781450391573},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3491102.3517728},
  doi = {10.1145/3491102.3517728},
  abstract = {“Virtual-Physical Perceptual Manipulations” (VPPMs) such as redirected walking and haptics expand the user’s capacity to interact with Virtual Reality (VR) beyond what would ordinarily physically be possible. VPPMs leverage knowledge of the limits of human perception to effect changes in the user’s physical movements, becoming able to (perceptibly and imperceptibly) nudge their physical actions to enhance interactivity in VR. We explore the risks posed by the malicious use of VPPMs. First, we define, conceptualize and demonstrate the existence of VPPMs. Next, using speculative design workshops, we explore and characterize the threats/risks posed, proposing mitigations and preventative recommendations against the malicious use of VPPMs. Finally, we implement two sample applications to demonstrate how existing VPPMs could be trivially subverted to create the potential for physical harm. This paper aims to raise awareness that the current way we apply and publish VPPMs can lead to malicious exploits of our perceptual vulnerabilities.},
  booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  articleno = {612},
  numpages = {15},
  keywords = {VPPM, VR security, physical harm, virtual-physical perceptual manipulation},
  location = {New Orleans, LA, USA},
  video = {https://www.youtube.com/watch?v=46qd0RQOQkc&ab_channel=ACMSIGCHI},
  pdf = {https://arxiv.org/abs/2202.13200},
  preview = {2022-darksides.jpg},
  series = {CHI '22}
}

@inproceedings{Bae2022,
  author = {Bae, S. Sandra and Zheng, Clement and West, Mary Etta and Do, Ellen Yi-Luen and Huron, Samuel and Szafir, Danielle Albers},
  title = {Making Data Tangible: A Cross-disciplinary Design Space for Data Physicalization},
  year = {2022},
  isbn = {9781450391573},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3491102.3501939},
  doi = {10.1145/3491102.3501939},
  abstract = {Designing a data physicalization requires a myriad of different considerations. Despite the cross-disciplinary nature of these considerations, research currently lacks a synthesis across the different communities data physicalization sits upon, including their approaches, theories, and even terminologies. To bridge these communities synergistically, we present a design space that describes and analyzes physicalizations according to three facets: context (end-user considerations), structure (the physical structure of the artifact), and interactions (interactions with both the artifact and data). We construct this design space through a systematic review of 47 physicalizations and analyze the interrelationships of key factors when designing a physicalization. This design space cross-pollinates knowledge from relevant HCI communities, providing a cohesive overview of what designers should consider when creating a data physicalization while suggesting new design possibilities. We analyze the design decisions present in current physicalizations, discuss emerging trends, and identify underlying open challenges.},
  booktitle = {Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems},
  articleno = {81},
  numpages = {18},
  keywords = {data physicalization, data visualization, design, design space, tangible user interface},
  location = {New Orleans, LA, USA},
  video = {https://www.youtube.com/watch?v=Mj1Oveo5_u0&ab_channel=ACMSIGCHI},
  website = {https://sandrabae.github.io/dataphys-gallery/index.html}, 
  preview = {2022-Making-Phys.png},
  series = {CHI '22}
}

@article{jolivet2021design,
  bibtex_show = {true},
  title = {Design territorial, repr{\'e}sentations spatiales et participation citoyenne: revue de cas et analyse d’outils},
  author = {Jolivet-Duval, Marion and Safin, St{\'e}phane and Huron, Samuel},
  abstract = {Territorial design is a recent field of practice whose definition has only been sketched out. Its emergence goes hand in hand with the evolution of the role and forms of territorial representations which have encouraged citizen participation in all its forms over the last twenty years. Although extensive research has been carried out on participatory design tools and methods, a taxonomy on the use of spatial representation techniques in the specific field of territorial design is still missing. Our research therefore extends and enhances existing work. An initial phase was dedicated to the collection and classification of 28 case studies based on two criteria initially established and descriptive categories progressively constituted. A second step con- sisted in elaborating visualizations which allowed us to identify development opportunities, such as the search for tools favouring the generation of ideas, the autonomy of participants or decentralised use.},
  journal = {Sciences du Design},
  number = {2},
  pages = {55--75},
  year = {2021},
  publisher = {Cairn/Softwin},
  preview = {2021-jolivet.png},
  pdf = {https://telecom-paris.hal.science/hal-03576813}
}

@article{frappier2021pour,
  bibtex_show={true},
  year = {2021},
  title={Pour une approche par le design des d{\'e}lib{\'e}rations},
  author={Frappier, Tallulah and Huron, Samuel},
  journal={Prendre soin de l'informatique et des g{\'e}n{\'e}rations},
  preview = {2021-design-deliberation.jpg},
  pdf = {https://hal.science/hal-03962953/},
  year={2021},
  publisher={FYP {\'e}ditions}
}
@article{saket2019investigating,
  bibtex_show={true},
  title={Investigating direct manipulation of graphical encodings as a method for user interaction},
  author={Saket, Bahador and Huron, Samuel and Perin, Charles and Endert, Alex},
  journal={IEEE transactions on visualization and computer graphics},
  video = {https://www.youtube.com/watch?v=i3JMmTKAB8o},
  pdf = {https://hal.science/hal-02260450v1/file/direct%20manipulation%20of%20graphical%20encodings.pdf},
  volume={26},
  number={1},
  pages={482--491},
  year={2019},
  publisher={IEEE}
}

@inproceedings{oehlberg2023making,
  title={Making with Data (and Beyond)},
  author={Oehlberg, Lora and Willett, Wesley and Huron, Samuel and Nagel, Till and Thudt, Alice and Ijeoma, Ekene and Offenhuber, Dietmar and Hornecker, Eva},
  booktitle={Extended Abstracts of the 2023 CHI Conference on Human Factors in Computing Systems},
  pdf={https://hal.sorbonne-universite.fr/INTERACT/hal-04491332v1},
  pages={1--5},
  year={2023}
}



@inproceedings{djavaherpour2021data,
  bibtex_show={true},
  title={Data to physicalization: A survey of the physical rendering process},
  author={Djavaherpour, Hessam and Samavati, Faramarz and Mahdavi-Amiri, Ali and Yazdanbakhsh, Fatemeh and Huron, Samuel and Levy, Richard and Jansen, Yvonne and Oehlberg, Lora},
  pdf={https://arxiv.org/abs/2102.11175},
  video={https://www.youtube.com/live/R-clpPl8Rgc?si=dEgBUPXFRFsL8flL&t=2545},
  booktitle={Computer Graphics Forum},
  volume={40},
  number={3},
  pages={569--598},
  year={2021}
}



@article{hall2019design,
  bibtex_show={true},
  title={Design by immersion: A transdisciplinary approach to problem-driven visualizations},
  author={Hall, Kyle Wm and Bradley, Adam J and Hinrichs, Uta and Huron, Samuel and Wood, Jo and Collins, Christopher and Carpendale, Sheelagh},
  journal={IEEE transactions on visualization and computer graphics},
  volume={26},
  number={1},
  pages={109--118},
  year={2019},
  publisher={IEEE}
}


@inproceedings{boukhelifa2017data,
  bibtex_show = {true},
  title = {How data workers cope with uncertainty: A task characterisation study},
  author = {Boukhelifa, Nadia and Perrin, Marc-Emmanuel and Huron, Samuel and Eagan, James},
  booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
  pages = {3645--3656},
  pdf = {https://hal.science/hal-01472865},
  video = {https://www.youtube.com/watch?v=lWXBNH_zCEI},
  annotation={* This paper received an Honorable Mention Award},
  preview={2017-characterizing-uncertainty.png},
  year = {2017}
}
@article{walny2017active,
  bibtex_show={true},
  title={Active reading of visualizations},
  author={Walny, Jagoda and Huron, Samuel and Perin, Charles and Wun, Tiffany and Pusch, Richard and Carpendale, Sheelagh},
  journal={IEEE transactions on visualization and computer graphics},
  volume={24},
  number={1},
  pages={770--780},
  year={2017},
  publisher={IEEE}
}
@inproceedings{wun2016comparing,
  bibtex_show={true},
  title={Comparing bar chart authoring with microsoft excel and tangible tiles},
  author={Wun, Tiffany and Payne, Jennifer and Huron, Samuel and Carpendale, Sheelagh},
  booktitle={Computer Graphics Forum},
  volume={35},
  number={3},
  pages={111--120},
  year={2016}
}
@inproceedings{lacroix2017paysage,
  bibtex_show={true},
  title={Paysage, la carte postale de la consommation {\'e}nerg{\'e}tique},
  author={Lacroix, Samuel and Huron, Samuel and Detienne, Fran{\c{c}}oise and Foissac, G},
  booktitle={29{\`e}me conf{\'e}rence francophone sur l'Interaction Homme-Machine},
  pages={8--p},
  year={2017}
}
@inproceedings{brule2017investigating,
  bibtex_show={true},
  title={Investigating the design space of smartwatches combining physical rotary inputs},
  author={Brul{\'e}, Emeline and Bailly, Gilles and Serrano, Marcos and Teyssier, Marc and Huron, Samuel},
  booktitle={Proceedings of the 29th Conference on l'Interaction Homme-Machine},
  pages={13--20},
  year={2017}
}
@incollection{drucker2018communicating,
  bibtex_show={true},
  title={Communicating data to an audience},
  author={Drucker, Steven and Huron, Samuel and Kosara, Robert and Schwabish, Jonathan and Diakopoulos, Nicholas},
  booktitle={Data-driven storytelling},
  pages={211--231},
  year={2018},
  publisher={AK Peters/CRC Press}
}
@inproceedings{mougenot2017tensions,
  bibtex_show={true},
  title={Tensions in creativity workshops},
  author={Mougenot, C{\'e}line and D{\'e}tienne, Fran{\c{c}}oise and Pennington, Miles and Baker, Michael and Corvin, Tim and Veyrier, Clair-Antoine and Arai, Kengo and Huron, Samuel},
  booktitle={Proceedings of the European Conference on Cognitive Ergonomics},
  pages={93--100},
  year={2017}
}

@inproceedings{Thudt2018,
  bibtex_show={true},
  author = {Thudt, Alice and Hinrichs, Uta and Huron, Samuel and Carpendale, Sheelagh},
  title = {Self-Reflection and Personal Physicalization Construction},
  year = {2018},
  isbn = {9781450356206},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3173574.3173728},
  doi = {10.1145/3173574.3173728},
  abstract = {Self-reflection is a central goal of personal informatics systems, and constructing visualizations from physical tokens has been found to help people reflect on data. However, so far, constructive physicalization has only been studied in lab environments with provided datasets. Our qualitative study investigates the construction of personal physicalizations in people's domestic environments over 2-4 weeks. It contributes an understanding of (1) the process of creating personal physicalizations, (2) the types of personal insights facilitated, (3) the integration of self-reflection in the physicalization process, and (4) its benefits and challenges for self-reflection. We found that in constructive personal physicalization, data collection, construction and self-reflections are deeply intertwined. This extends previous models of visualization creation and data-driven self-reflection. We outline how benefits such as reflection through manual construction, personalization, and presence in everyday life can be transferred to a wider set of digital and physical systems.},
  booktitle = {Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems},
  pages = {1–13},
  numpages = {13},
  keywords = {self-reflection, personal data, constructive visualization},
  location = {Montreal QC, Canada},
  series = {CHI '18}
}

@inproceedings{huron2017let,
  bibtex_show={true},
  title={Let's get physical: Promoting data physicalization in workshop formats},
  author={Huron, Samuel and Gourlet, Pauline and Hinrichs, Uta and Hogan, Trevor and Jansen, Yvonne},
  booktitle={Proceedings of the 2017 Conference on Designing Interactive Systems},
  pdf = {https://hal.sorbonne-universite.fr/hal-01538595},
  preview={2017-lets-get-physical.png},
  pages={1409--1422},
  year={2017}
}
@inproceedings{mougenot2017tensions,
  bibtex_show={true},
  title={Tensions in creativity workshops},
  author={Mougenot, C{\'e}line and D{\'e}tienne, Fran{\c{c}}oise and Pennington, Miles and Baker, Michael and Corvin, Tim and Veyrier, Clair-Antoine and Arai, Kengo and Huron, Samuel},
  booktitle={Proceedings of the European Conference on Cognitive Ergonomics},
  pages={93--100},
  year={2017}
}


@inproceedings{le2016better,
  bibtex_show={true},
  title={A better grasp on pictures under glass: Comparing touch and tangible object manipulation using physical proxies},
  author={Le Goc, Mathieu and Dragicevic, Pierre and Huron, Samuel and Boy, Jeremy and Fekete, Jean-Daniel},
  booktitle={Proceedings of the International Working Conference on Advanced Visual Interfaces},
  pages={76--83},
  year={2016}
}
@inproceedings{huron2016using,
  bibtex_show={true},
  title={Using viskit: A manual for running a constructive visualization workshop},
  author={Huron, Samuel and Carpendale, Sheelagh and Boy, Jeremy and Fekete, Jean-Daniel},
  booktitle={Pedagogy of Data Visualization Workshop at IEEE VIS 2016},
  year={2016}
}

@inproceedings{willett2016constructive,
  bibtex_show={true},
  title={A constructive classroom exercise for teaching infovis},
  author={Willett, Wesley and Huron, Samuel},
  booktitle={Pedagogy of Data Visualization Workshop at IEEE VIS 2016},
  year={2016}
}


@article{thudt2015visual,
  bibtex_show={true},
  title={Visual mementos: Reflecting memories with personal data},
  author={Thudt, Alice and Baur, Dominikus and Huron, Samuel and Carpendale, Sheelagh},
  journal={IEEE transactions on visualization and computer graphics},
  volume={22},
  number={1},
  pages={369--378},
  year={2015},
  preview={2015-visual-mementos.png},
  video={https://vimeo.com/236169885},
  publisher={IEEE}
}

@inproceedings{walny2015exploratory,
  bibtex_show={true},
  title={An exploratory study of data sketching for visual representation},
  abstract={Hand-drawn sketching on napkins or whiteboards is a common, accessible method for generating visual representations. This practice is shared by experts and non-experts and is probably one of the faster and more expressive ways to draft a visual representation of data. In order to better understand the types of and variations in what people produce when sketching data, we conducted a qualitative study. We asked people with varying degrees of visualization expertise, from novices to experts, to manually sketch representations of a small, easily understandable dataset using pencils and paper and to report on what they learned or found interesting about the data. From this study, we extract a data sketching representation continuum from numeracy to abstraction; a data report spectrum from individual data items to speculative data hypothesis; and show the correspondence between the representation types and the data reports from our results set. From these observations we discuss the participants’ representations in relation to their data reports, indicating implications for design and potentially fruitful directions for research.},
  author={Walny, Jagoda and Huron, Samuel and Carpendale, Sheelagh},
  booktitle={Computer Graphics Forum},
  volume={34},
  number={3},
  pages={231--240},
  preview={2015-data-sketching.png},
  pdf={https://inria.hal.science/hal-01024053/document},
  selected={true},
  year={2015}
}

@article{huron2014constructing,
  bibtex_show={true},
  author={Huron, Samuel and Jansen, Yvonne and Carpendale, Sheelagh},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Constructing Visual Representations: Investigating the Use of Tangible Tokens}, 
  year={2014},
  volume={20},
  number={12},
  pages={2102-2111},
  keywords={Data visualization;Authoring tools;Image color analysis;Encoding;Publishing;Context awareness;Constructive visualization;Physical visualization;Dynamic visualization;Empirical study;Token;Visualization authoring;Information visualization;Visual mapping;Novices;Visualization construction;Visual analytics},
  doi={10.1109/TVCG.2014.2346292},
  video={https://www.youtube-nocookie.com/embed/_16WZgu85uw},
  preview={2014-constructing.png},
  selected={true},
  pdf={https://inria.hal.science/hal-01024053/document}
}

@inproceedings{ConstructiveVisualization,
  bibtex_show={true},
  author = {Huron, Samuel and Carpendale, Sheelagh and Thudt, Alice and Tang, Anthony and Mauerer, Michael},
  title = {Constructive visualization},
  year = {2014},
  isbn = {9781450329026},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/2598510.2598566},
  doi = {10.1145/2598510.2598566},
  abstract = {If visualization is to be democratized, we need to provide means for non-experts to create visualizations that allow them to engage directly with datasets. We present constructive visualization a new paradigm for the simple creation of flexible, dynamic visualizations. Constructive visualization is simple-in that the skills required to build and manipulate the visualizations are akin to kindergarten play; it is expressive in that one can build within the constraints of the chosen environment, and it also supports dynamics -- in that these constructed visualizations can be rebuilt and adjusted. We de- scribe the conceptual components and processes underlying constructive visualization, and present real-world examples to illustrate the utility of this approach. The constructive visualization approach builds on our inherent understanding and experience with physical building blocks, offering a model that enables non-experts to create entirely novel visualizations, and to engage with datasets in a manner that would not have otherwise been possible.},
  booktitle = {Proceedings of the 2014 Conference on Designing Interactive Systems},
  pages = {433–442},
  numpages = {10},
  keywords = {visualization, visual literacy., education, design, constructivism, constructionism, construction, assembling},
  location = {Vancouver, BC, Canada},
  series = {DIS '14},
  preview={2014-constructive-vis.png},
  selected={true},
  pdf={https://inria.hal.science/hal-00978437/PDF/constructive-visualization-author-version.pdf}
}

@ARTICLE{Huron2013VisualSedimentation,
  bibtex_show={true},
  author={Huron, Samuel and Vuillemot, Romain and Fekete, Jean-Daniel},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={Visual Sedimentation}, 
  abstract ={We introduce Visual Sedimentation, a novel design metaphor for visualizing data streams directly inspired by the physical process of sedimentation. Visualizing data streams (e. g., Tweets, RSS, Emails) is challenging as incoming data arrive at unpredictable rates and have to remain readable. For data streams, clearly expressing chronological order while avoiding clutter, and keeping aging data visible, are important. The metaphor is drawn from the real-world sedimentation processes: objects fall due to gravity, and aggregate into strata over time. Inspired by this metaphor, data is visually depicted as falling objects using a force model to land on a surface, aggregating into strata over time. In this paper, we discuss how this metaphor addresses the specific challenge of smoothing the transition between incoming and aging data. We describe the metaphor's design space, a toolkit developed to facilitate its implementation, and example applications to a range of case studies. We then explore the generative capabilities of the design space through our toolkit. We finally illustrate creative extensions of the metaphor when applied to real streams of data.},
  year={2013},
  volume={19},
  number={12},
  pages={2446-2455},
  preview={2013-VisualSedimentation.png},
  pdf={https://inria.hal.science/hal-00846260},
  video={https://www.youtube-nocookie.com/embed/woBJMNwWK0w},
  keywords={Data visualization;Sediments;Design methodology;Real-time systems;Data visualization;Sediments;Design methodology;Real-time systems;metaphor;Design;information visualization;dynamic visualization;dynamic data;data stream;real time},
  doi={10.1109/TVCG.2013.227}
}


@inproceedings{huron2013polemictweet,
  bibtex_show={true},
  title={PolemicTweet: Video annotation and analysis through tagged tweets},
  author={Huron, Samuel and Isenberg, Petra and Fekete, Jean Daniel},
  booktitle={Human-Computer Interaction--INTERACT 2013: 14th IFIP TC 13 International Conference, Cape Town, South Africa, September 2-6, 2013, Proceedings, Part II 14},
  abstract = {We present PolemicTweet a system with an encompassing, economic, and engaging approach to video tagging and analysis. Annotating and tagging videos manually is a boring and time-consuming process. Yet, in the last couple of years the audiences of events--such as academic conferences--have begun to produce unexploited metadata in the form of micropost activities. With PolemicTweet we explore the use of tagged microposts for both video an- notation and browsing aid. PolemicTweet is a system 1) to crowd source conference video tagging with structured sentiment metadata, 2) to engage audiences in a tagging process, and 3) to visualize these annotations for browsing and analyzing a video. We describe the the system and its components as well as the results from a one-year live deployment in 27 different events.},
  website = {https://polemictweet.com/},
  preview={2013-polemic-tweet.jpg},
  pdf={https://inria.hal.science/hal-00817591},
  pages={135--152},
  year={2013},
  annotation={* This paper received an Award},
  organization={Springer Berlin Heidelberg}
}

@inproceedings{mazieres2013toward,
  bibtex_show={true},
  title={Toward Google Borders},
  abstract ={Query logs let by user on search-engines have helped create efficient tools for trend analysis, from commercial use to forecasting epidemics. In this paper, we propose a new method and system for cultural trends analysis based on Google auto-complete suggestions. We present Zeitgeist Borders, a toolkit enabling any user to collect and analyze associations between queries, suggestions and various regions of the world. We report unexpected observations about several behavioural and geographical trends along with promising uses.},
  author={Mazieres, Antoine and Huron, Samuel},
  booktitle={Proceedings of the 5th Annual ACM Web Science Conference},
  preview={2013-google-borders.png},
  pages={244--247},
  year={2013}
}



@inproceedings{SoftBioMorph,
  bibtex_show={true},
  author = {Nicolae, Madalina and Lefez, Claire and Roudaut, Anne and Huron, Samuel and Steimle, J\"{u}rgen and Teyssier, Marc},
  title = {SoftBioMorph: Fabricating Sustainable Shape-changing Interfaces using Soft Biopolymers},
  year = {2024},
  isbn = {9798400705830},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3643834.3661610},
  doi = {10.1145/3643834.3661610},
  abstract = {Bio-based and bio-degradable materials have shown promising results for sustainable Human-Computer Interaction (HCI) applications, including shape-changing interfaces. However, the diversity of shape-changing behaviors achievable with these materials remains unclear as the fabrication knowledge is scattered across multiple research fields. This paper introduces SoftBioMorph, a fabrication framework that aims to integrate the fabrication know-how of sustainable soft shape-changing interfaces with biopolymers. Based on the example of Sodium Alginate, the framework contributes (1) a set of material synthesis processes that modify the biopolymer’s properties to fulfill different functions; (2) a set of DIY crafting-based assembling techniques that functionalize the material and assembling properties to achieve three primitive types of change in shape; and (3) a series of application cases that demonstrate the versatility of the framework. We further discuss limitations, research questions, and fabrication challenges, presenting a comprehensive approach to sustainable prototyping in HCI.},
  booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
  pages = {496–508},
  numpages = {13},
  keywords = {DIY, biomaterials, bioplastics, biopolymers, fabrication, prototyping, shape-changing interface, sustainability, tangible interfaces},
  location = {Copenhagen, Denmark},
  series = {DIS '24},
  video={https://www.youtube-nocookie.com/embed/HkEnuYZDb9k},
  preview={2024-softbiomorph.png},
  selected={true},
  series = {CHI '24},
  pdf={https://dl.acm.org/doi/abs/10.1145/3643834.3661610}
}

@inproceedings{Nicolae2023,
  bibtex_show={true},
  author = {Nicolae, Madalina and Roussel, Vivien and Koelle, Marion and Huron, Samuel and Steimle, J\"{u}rgen and Teyssier, Marc},
  title = {Biohybrid Devices: Prototyping Interactive Devices with Growable Materials},
  year = {2023},
  isbn = {9798400701320},
  publisher = {Association for Computing Machinery},
  address = {New York, NY, USA},
  url = {https://doi.org/10.1145/3586183.3606774},
  doi = {10.1145/3586183.3606774},
  abstract = {Living bio-materials are increasingly used in HCI for fabricating objects by growing. However, how to integrate electronics to make these objects interactive still needs to be clarified. This paper presents an exploration of the fabrication design space of Biohybrid Interactive Devices, a class of interactive devices fabricated by merging electronic components and living organisms. From the exploration of this space using bacterial cellulose, we outline a fabrication framework centered on the biomaterials‘ life cycle phases. We introduce a set of novel fabrication techniques for embedding conductive elements, sensors, and output components through biological (e.g. bio-fabrication and bio-assembling) and digital processes. We demonstrate the combinatory aspect of the framework by realizing three tangible, wearable, and shape-changing interfaces. Finally, we discuss the sustainability of our approach, its limitations, and the implications for bio-hybrid systems in HCI.},
  booktitle = {Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology},
  articleno = {31},
  numpages = {15},
  video={https://www.youtube-nocookie.com/embed/w5ecPikgSTo},
  preview={2023-biohybrid.jpg},
  location = {San Francisco, CA, USA},
  series = {UIST '23},
  selected={true}
}

