<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Samuel Huron </title> <meta name="author" content="Samuel Huron"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://samuel-huron.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/funding/">Funding </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">People </a> </li> <li class="nav-item "> <a class="nav-link" href="/video/">Video </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Samuel</span> Huron </h1> <p class="desc">Associate Professor in Interaction Design at the Social Science Departement, Institute Polytechnique de Paris.</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/Samuel-Huron-Emmanuelle-Marchadour.png" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/Samuel-Huron-Emmanuelle-Marchadour.png?029cd0840da7de0fdc362e5b07d44dae" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="Samuel-Huron-Emmanuelle-Marchadour.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am an interaction designer and computer scientist; my research focuses on new media, Interaction Design, Human-Computer Interaction, physical representation of data, and social computing. In particular, I am investigating how humans create representations of data, how we can study digital technology’s negative impact before it occurs, and how we can make digital technology more sustainable. I recently co-edited the book “<a href="https://makingwithdata.org/" rel="external nofollow noopener" target="_blank">Making with Data: Physical Design and Craft in a Data-Driven World</a>” with Till Nagel, Lora Oehlberg, and Wesley Willett.</p> <p>On the research side, I am co-chair of the Axis “<a href="https://i3.cnrs.fr/axes-de-recherche/theorie-et-modeles-de-la-conception/" rel="external nofollow noopener" target="_blank">Theory, practice, and politics of design and creative action</a>” of the i3 CNRS Lab with Pascal Lemasson and co-chair of the Design seminar for the PEPR ICCAR. On the teaching side, I am also co-heading the Master program Design Recherche with ENS, ENSCI, and Télécom and the Executive Education Mastère program on Innovation and entrepreneurship in collaboration with Zhejiang University, Polytechnique, ENSTA, and Télécom.</p> <p>My academic journey includes a postdoctoral fellowship at the I Lab in the Innovis group under the supervision of <a href="http://sheelaghcarpendale.ca/" rel="external nofollow noopener" target="_blank">Sheelagh Caprendale</a> at the University of Calgary. Prior to that, I pursued my PhD in the <a href="https://www.aviz.fr/" rel="external nofollow noopener" target="_blank">Aviz</a> group at <a href="https://www.inria.fr/fr/centre-inria-de-saclay" rel="external nofollow noopener" target="_blank">INRIA Saclay</a>, completing it with the Université Paris Sud under the guidance of Jean-Daniel Fekete and in collaboration with the <a href="https://www.iri.centrepompidou.fr/" rel="external nofollow noopener" target="_blank">research institute of the Pompidou Center</a> (IRI). My Ph.D. in Constructive Visualization was recognized with the ‘<a href="https://tc.computer.org/vgtc/awards/vis-doctoral-dissertation-award/" rel="external nofollow noopener" target="_blank">Best Doctoral Dissertation Award</a>’ from IEEE VGTC Pioneer Group. During my Ph.D. I also served as the lead design of the Research Institute of the Pompidou Center (IRI).</p> <p>I have a deep passion for interdisciplinary work, which is reflected in my academic journey. Before my Ph.D., I received a Master of Fine Art in New Media from the Université Panthéon Sorbonne under the supervision of Anne Marie Duguet. I also received a Master 1 in Information and Communication Sciences from the Université Paris 8, based on my industrial work, and studied Philosophy and Psychology in my first years of bachelor at the Université Paris 8. I also had the opportunity to work with the group’s Image Temps Reel and Extension du Reel at ENSAD Lab. I co-founded the hackerspace Fabelier and followed the Web Science Master at the CRI.</p> <p>Before my academic career, between 1999 and 2010, I had an industrial career as a designer in multiple digital communication agencies. I designed, developed, and supervised hundreds of interactive media projects where I worked with a broad range of civic, cultural, and corporate clients. At that time, I was engaged as a new media artist, collaborating with a video art label on an art installation, video mixing, and live performances. I presented and performed some of our artwork in different shows or exhibitions, including art museums, parties, and festivals…</p> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Dec 03, 2025</th> <td> I succuesfull defended my HDR (Habiliation à Diriger Des Recherche) at <a href="https://www.ip-paris.fr/" rel="external nofollow noopener" target="_blank">Institut Polytechnique de Paris</a>, I will try to upload the document and slides on this page when I have the time <a href="https://samuel-huron.github.io/blog/2025/HDR-samuel-huron-supplemental/">HDR post</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Nov 02, 2025</th> <td> Between the 01/11 to 07/11, I was at IEEE VIS in Vienna, for organizing the <a href="https://inputvisualization.github.io/vis2025/" rel="external nofollow noopener" target="_blank">Input visualization workshop</a> and for participating to the panel discussion about <a href="https://sites.google.com/view/isotype/panel-discussion" rel="external nofollow noopener" target="_blank">Otto Neurath - “Words divide, pictures unite” - Revisiting Otto Neurath’s Isotype at 100</a>. Also Anne Flore Cabouat was presenting <a href="https://telecom-paris.hal.science/I3-TPT/hal-05218370v1" rel="external nofollow noopener" target="_blank">Bridging Educational Theories of Cognitive Load to Visualization Design and Evaluation</a> and June Bhartia was presenting Exploring Touch Interactions for Input Visualization in Personal Informatics. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 23, 2024</th> <td> The 9th of December 2024 we will organize a Young Researcher/Designer’s Day on <em>“Theory, Practice and Politics of Design and Creative Action”</em> at Écoles des Mines in Paris. We have an open call for your researcher in design. The final deadline is the 28/11/2024 <a href="https://samuel-huron.github.io/assets/pdf/2024-12_Journee-Jeune-Chercheur-%20appel%20contribution.pdf">Here is the call</a>. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 23, 2024</th> <td> I have the pleasure to co-organise the ACM ISS workshop on <a href="https://summit.sfu.ca/_flysystem/fedora/2024-08/ISS24_workshop_zezhong.pdf" rel="external nofollow noopener" target="_blank"><em>Visual Methods and Analyzing Visual Data in Human Computer Interaction</em></a>. The workshop will take place in Vancouver Canada but remote attendance are allowed ! If you are interested join us. </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 16, 2024</th> <td> I will be part of the panel ``<a href="https://shuxinhuan.github.io/visap-panel/" rel="external nofollow noopener" target="_blank">What Do Visualization Art Projects Bring to the VIS Community?</a> “ Wednesday, October 16th, from 8:30 AM to 9:45 AM, EDT (UTC-4). at IEEE VIS </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2024-Jumping-to-conclusion.jpeg" sizes="200px"> <img src="/assets/img/publication_preview/2024-Jumping-to-conclusion.jpeg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2024-Jumping-to-conclusion.jpeg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="frappier2024jumping" class="col-sm-8"> <div class="title">Jumping to Conclusions: A Visual Comparative Analysis of Online Debate Platform Layouts</div> <div class="author"> Tallullah Frappier, Nathalie Bressa, and <em>Samuel Huron</em> </div> <div class="periodical"> <em>In Proceedings of the 13th Nordic Conference on Human-Computer Interaction</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://osf.io/43pg9" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>There has been an increase in online debate platforms in recent years that allow individuals to exchange their opinions or to foster civic engagement. Even though the design of platforms has a significant influence on the quality of debates, research has yet to systematically analyze the graphical user interfaces of debate tools that are currently in use. To address this, we collected 25 off-the-shelf online debate platforms and conducted a comparative visual analysis of their graphical user interfaces. We identified different types of platforms, interface blocks, hierarchies, and display layout patterns. We found a strong similarity among these platforms in their design and a shared emphasis on individual input. Drawing from these insights, we discuss how the design of platforms frames the practice of debate and identify potential design dimensions in order to move beyond the existing boundaries of online debate.</p> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2024-chi-table1.png" sizes="200px"> <img src="/assets/img/publication_preview/2024-chi-table1.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2024-chi-table1.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Bressa2024" class="col-sm-8"> <div class="title">Input Visualization: Collecting and Modifying Data with Visual Representations</div> <div class="author"> Nathalie Bressa, Jordan Louis, Wesley Willett, and <em>Samuel Huron</em> </div> <div class="periodical"> <em>In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</em>, Honolulu, HI, USA, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://osf.io/c9j8s" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube-nocookie.com/embed/wilUZ5wbTiw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>We examine input visualizations, visual representations that are designed to collect (and represent) new data rather than encode preexisting datasets. Information visualization is commonly used to reveal insights and stories within existing data. As a result, most contemporary visualization approaches assume existing datasets as the starting point for design, through which that data is mapped to visual encodings. Meanwhile, the implications of visualizations as inputs and as data sources have received little attention—despite the existence of visual and physical examples stretching back centuries. In this paper, we present a design space of 50 input visualizations analyzing their visual representation, data, artifact, context, and input. Based on this, we identify input modalities, purposes of input visualizations, and a set of design considerations. Finally, we discuss the relationship between input visualization and traditional visualization design and suggest opportunities for future research to better understand these visual representations and their potential.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Bressa2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bressa, Nathalie and Louis, Jordan and Willett, Wesley and Huron, Samuel}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Input Visualization: Collecting and Modifying Data with Visual Representations}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400703300}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://osf.io/bw3gp/?view_only=}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3613904.3642808}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{499}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{18}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{data collection, data discussion, input visualization, interaction, participation, physicalization, public engagement, survey, visualization}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Honolulu, HI, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2024-source-confusion.jpg" sizes="200px"> <img src="/assets/img/publication_preview/2024-source-confusion.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2024-source-confusion.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Bonnail2024" class="col-sm-8"> <div class="title">Was it Real or Virtual? Confirming the Occurrence and Explaining Causes of Memory Source Confusion between Reality and Virtual Reality</div> <div class="author"> Elise Bonnail, Julian Frommel, Eric Lecolinet, <em>Samuel Huron</em>, and Jan Gugenheimer </div> <div class="periodical"> <em>In Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</em>, Honolulu, HI, USA, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.youtube-nocookie.com/embed/NagIRCvq-Eo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Source confusion occurs when individuals attribute a memory to the wrong source (e.g., confusing a picture with an experienced event). Virtual Reality (VR) represents a new source of memories particularly prone to being confused with reality. While previous research identified causes of source confusion between reality and other sources (e.g., imagination, pictures), there is currently no understanding of what characteristics specific to VR (e.g., immersion, presence) could influence source confusion. Through a laboratory study (n=29), we 1) confirm the existence of VR source confusion with current technology, and 2) present a quantitative and qualitative exploration of factors influencing VR source confusion. Building on the Source Monitoring Framework, we identify VR characteristics and assumptions about VR capabilities (e.g., poor rendering) that are used to distinguish virtual from real memories. From these insights, we reflect on how the increasing realism of VR could leave users vulnerable to memory errors and perceptual manipulations.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Bonnail2024</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bonnail, Elise and Frommel, Julian and Lecolinet, Eric and Huron, Samuel and Gugenheimer, Jan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Was it Real or Virtual? Confirming the Occurrence and Explaining Causes of Memory Source Confusion between Reality and Virtual Reality}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400703300}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3613904.3641992}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3613904.3641992}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{796}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Memory, Source Confusion, Source Misattribution, Virtual Reality}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Honolulu, HI, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '24}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2023-Memory-manipulation.png" sizes="200px"> <img src="/assets/img/publication_preview/2023-Memory-manipulation.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023-Memory-manipulation.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Bonnail2023" class="col-sm-8"> <div class="title">Memory Manipulations in Extended Reality</div> <div class="author"> Elise Bonnail, Wen-Jie Tseng, Mark Mcgill, Eric Lecolinet, <em>Samuel Huron</em>, and Jan Gugenheimer <i class="fa-solid fa-circle-info ml-1" data-toggle="popover" data-placement="top" data-html="true" data-content="* This paper received an Honorable Mention Award"> </i> </div> <div class="periodical"> <em>In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems</em>, Hamburg, Germany, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://hal.science/I3-TPT/hal-04058016v1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube-nocookie.com/embed/iGIdRoINgsw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Human memory has notable limitations (e.g., forgetting) which have necessitated a variety of memory aids (e.g., calendars). As we grow closer to mass adoption of everyday Extended Reality (XR), which is frequently leveraging perceptual limitations (e.g., redirected walking), it becomes pertinent to consider how XR could leverage memory limitations (forgetting, distorting, persistence) to induce memory manipulations. As memories highly impact our self-perception, social interactions, and behaviors, there is a pressing need to understand XR Memory Manipulations (XRMMs). We ran three speculative design workshops (n=12), with XR and memory researchers creating 48 XRMM scenarios. Through thematic analysis, we define XRMMs, present a framework of their core components and reveal three classes (at encoding, pre-retrieval, at retrieval). Each class differs in terms of technology (AR, VR) and impact on memory (influencing quality of memories, inducing forgetting, distorting memories). We raise ethical concerns and discuss opportunities of perceptual and memory manipulations in XR.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Bonnail2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bonnail, Elise and Tseng, Wen-Jie and Mcgill, Mark and Lecolinet, Eric and Huron, Samuel and Gugenheimer, Jan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Memory Manipulations in Extended Reality}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450394215}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3544548.3580988}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3544548.3580988}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{875}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Augmented Reality, Extended Reality, Perceptual Manipulations, Speculative Design, Virtual Reality, XR Memory Manipulations}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Hamburg, Germany}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '23}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2022-darksides.jpg" sizes="200px"> <img src="/assets/img/publication_preview/2022-darksides.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2022-darksides.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Tseng2022" class="col-sm-8"> <div class="title">The Dark Side of Perceptual Manipulations in Virtual Reality</div> <div class="author"> Wen-Jie Tseng, Elise Bonnail, Mark McGill, Mohamed Khamis, Eric Lecolinet, <em>Samuel Huron</em>, and Jan Gugenheimer </div> <div class="periodical"> <em>In Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</em>, New Orleans, LA, USA, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2202.13200" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube.com/watch?v=46qd0RQOQkc&amp;ab_channel=ACMSIGCHI" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>“Virtual-Physical Perceptual Manipulations” (VPPMs) such as redirected walking and haptics expand the user’s capacity to interact with Virtual Reality (VR) beyond what would ordinarily physically be possible. VPPMs leverage knowledge of the limits of human perception to effect changes in the user’s physical movements, becoming able to (perceptibly and imperceptibly) nudge their physical actions to enhance interactivity in VR. We explore the risks posed by the malicious use of VPPMs. First, we define, conceptualize and demonstrate the existence of VPPMs. Next, using speculative design workshops, we explore and characterize the threats/risks posed, proposing mitigations and preventative recommendations against the malicious use of VPPMs. Finally, we implement two sample applications to demonstrate how existing VPPMs could be trivially subverted to create the potential for physical harm. This paper aims to raise awareness that the current way we apply and publish VPPMs can lead to malicious exploits of our perceptual vulnerabilities.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Tseng2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Tseng, Wen-Jie and Bonnail, Elise and McGill, Mark and Khamis, Mohamed and Lecolinet, Eric and Huron, Samuel and Gugenheimer, Jan}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{The Dark Side of Perceptual Manipulations in Virtual Reality}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450391573}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3491102.3517728}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3491102.3517728}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{612}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{VPPM, VR security, physical harm, virtual-physical perceptual manipulation}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{New Orleans, LA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '22}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2015-data-sketching.png" sizes="200px"> <img src="/assets/img/publication_preview/2015-data-sketching.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2015-data-sketching.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="walny2015exploratory" class="col-sm-8"> <div class="title">An exploratory study of data sketching for visual representation</div> <div class="author"> Jagoda Walny, <em>Samuel Huron</em>, and Sheelagh Carpendale </div> <div class="periodical"> <em>In Computer Graphics Forum</em>, 2015 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://inria.hal.science/hal-01024053/document" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>Hand-drawn sketching on napkins or whiteboards is a common, accessible method for generating visual representations. This practice is shared by experts and non-experts and is probably one of the faster and more expressive ways to draft a visual representation of data. In order to better understand the types of and variations in what people produce when sketching data, we conducted a qualitative study. We asked people with varying degrees of visualization expertise, from novices to experts, to manually sketch representations of a small, easily understandable dataset using pencils and paper and to report on what they learned or found interesting about the data. From this study, we extract a data sketching representation continuum from numeracy to abstraction; a data report spectrum from individual data items to speculative data hypothesis; and show the correspondence between the representation types and the data reports from our results set. From these observations we discuss the participants’ representations in relation to their data reports, indicating implications for design and potentially fruitful directions for research.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">walny2015exploratory</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An exploratory study of data sketching for visual representation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Walny, Jagoda and Huron, Samuel and Carpendale, Sheelagh}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Computer Graphics Forum}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{231--240}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2015}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2014-constructing.png" sizes="200px"> <img src="/assets/img/publication_preview/2014-constructing.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2014-constructing.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="huron2014constructing" class="col-sm-8"> <div class="title">Constructing Visual Representations: Investigating the Use of Tangible Tokens</div> <div class="author"> <em>Samuel Huron</em>, Yvonne Jansen, and Sheelagh Carpendale </div> <div class="periodical"> <em>IEEE Transactions on Visualization and Computer Graphics</em>, 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://inria.hal.science/hal-01024053/document" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube-nocookie.com/embed/_16WZgu85uw" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">huron2014constructing</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huron, Samuel and Jansen, Yvonne and Carpendale, Sheelagh}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Transactions on Visualization and Computer Graphics}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Constructing Visual Representations: Investigating the Use of Tangible Tokens}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{20}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2102-2111}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Data visualization;Authoring tools;Image color analysis;Encoding;Publishing;Context awareness;Constructive visualization;Physical visualization;Dynamic visualization;Empirical study;Token;Visualization authoring;Information visualization;Visual mapping;Novices;Visualization construction;Visual analytics}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/TVCG.2014.2346292}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2014-constructive-vis.png" sizes="200px"> <img src="/assets/img/publication_preview/2014-constructive-vis.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2014-constructive-vis.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="ConstructiveVisualization" class="col-sm-8"> <div class="title">Constructive visualization</div> <div class="author"> <em>Samuel Huron</em>, Sheelagh Carpendale, Alice Thudt, Anthony Tang, and Michael Mauerer </div> <div class="periodical"> <em>In Proceedings of the 2014 Conference on Designing Interactive Systems</em>, Vancouver, BC, Canada, 2014 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://inria.hal.science/hal-00978437/PDF/constructive-visualization-author-version.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="abstract hidden"> <p>If visualization is to be democratized, we need to provide means for non-experts to create visualizations that allow them to engage directly with datasets. We present constructive visualization a new paradigm for the simple creation of flexible, dynamic visualizations. Constructive visualization is simple-in that the skills required to build and manipulate the visualizations are akin to kindergarten play; it is expressive in that one can build within the constraints of the chosen environment, and it also supports dynamics – in that these constructed visualizations can be rebuilt and adjusted. We de- scribe the conceptual components and processes underlying constructive visualization, and present real-world examples to illustrate the utility of this approach. The constructive visualization approach builds on our inherent understanding and experience with physical building blocks, offering a model that enables non-experts to create entirely novel visualizations, and to engage with datasets in a manner that would not have otherwise been possible.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ConstructiveVisualization</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Huron, Samuel and Carpendale, Sheelagh and Thudt, Alice and Tang, Anthony and Mauerer, Michael}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Constructive visualization}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2014}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781450329026}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/2598510.2598566}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/2598510.2598566}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2014 Conference on Designing Interactive Systems}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{433–442}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{10}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{visualization, visual literacy., education, design, constructivism, constructionism, construction, assembling}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Vancouver, BC, Canada}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{DIS '14}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2024-softbiomorph.png" sizes="200px"> <img src="/assets/img/publication_preview/2024-softbiomorph.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2024-softbiomorph.png" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="SoftBioMorph" class="col-sm-8"> <div class="title">SoftBioMorph: Fabricating Sustainable Shape-changing Interfaces using Soft Biopolymers</div> <div class="author"> Madalina Nicolae, Claire Lefez, Anne Roudaut, <em>Samuel Huron</em>, Jürgen Steimle, and Marc Teyssier </div> <div class="periodical"> <em>In Proceedings of the 2024 ACM Designing Interactive Systems Conference</em>, Copenhagen, Denmark, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/abs/10.1145/3643834.3661610" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://www.youtube-nocookie.com/embed/HkEnuYZDb9k" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Bio-based and bio-degradable materials have shown promising results for sustainable Human-Computer Interaction (HCI) applications, including shape-changing interfaces. However, the diversity of shape-changing behaviors achievable with these materials remains unclear as the fabrication knowledge is scattered across multiple research fields. This paper introduces SoftBioMorph, a fabrication framework that aims to integrate the fabrication know-how of sustainable soft shape-changing interfaces with biopolymers. Based on the example of Sodium Alginate, the framework contributes (1) a set of material synthesis processes that modify the biopolymer’s properties to fulfill different functions; (2) a set of DIY crafting-based assembling techniques that functionalize the material and assembling properties to achieve three primitive types of change in shape; and (3) a series of application cases that demonstrate the versatility of the framework. We further discuss limitations, research questions, and fabrication challenges, presenting a comprehensive approach to sustainable prototyping in HCI.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">SoftBioMorph</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nicolae, Madalina and Lefez, Claire and Roudaut, Anne and Huron, Samuel and Steimle, J\"{u}rgen and Teyssier, Marc}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{SoftBioMorph: Fabricating Sustainable Shape-changing Interfaces using Soft Biopolymers}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400705830}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3643834.3661610}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3643834.3661610}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2024 ACM Designing Interactive Systems Conference}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{496–508}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{13}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{DIY, biomaterials, bioplastics, biopolymers, fabrication, prototyping, shape-changing interface, sustainability, tangible interfaces}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{Copenhagen, Denmark}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CHI '24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/2023-biohybrid.jpg" sizes="200px"> <img src="/assets/img/publication_preview/2023-biohybrid.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="2023-biohybrid.jpg" data-zoomable loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="Nicolae2023" class="col-sm-8"> <div class="title">Biohybrid Devices: Prototyping Interactive Devices with Growable Materials</div> <div class="author"> Madalina Nicolae, Vivien Roussel, Marion Koelle, <em>Samuel Huron</em>, Jürgen Steimle, and Marc Teyssier </div> <div class="periodical"> <em>In Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology</em>, San Francisco, CA, USA, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.youtube-nocookie.com/embed/w5ecPikgSTo" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Video</a> </div> <div class="abstract hidden"> <p>Living bio-materials are increasingly used in HCI for fabricating objects by growing. However, how to integrate electronics to make these objects interactive still needs to be clarified. This paper presents an exploration of the fabrication design space of Biohybrid Interactive Devices, a class of interactive devices fabricated by merging electronic components and living organisms. From the exploration of this space using bacterial cellulose, we outline a fabrication framework centered on the biomaterials‘ life cycle phases. We introduce a set of novel fabrication techniques for embedding conductive elements, sensors, and output components through biological (e.g. bio-fabrication and bio-assembling) and digital processes. We demonstrate the combinatory aspect of the framework by realizing three tangible, wearable, and shape-changing interfaces. Finally, we discuss the sustainability of our approach, its limitations, and the implications for bio-hybrid systems in HCI.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Nicolae2023</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Nicolae, Madalina and Roussel, Vivien and Koelle, Marion and Huron, Samuel and Steimle, J\"{u}rgen and Teyssier, Marc}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Biohybrid Devices: Prototyping Interactive Devices with Growable Materials}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9798400701320}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3586183.3606774}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3586183.3606774}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 36th Annual ACM Symposium on User Interface Software and Technology}</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{31}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{15}</span><span class="p">,</span>
  <span class="na">location</span> <span class="p">=</span> <span class="s">{San Francisco, CA, USA}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{UIST '23}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> --&gt; <div class="social"> <div class="contact-icons"> <a href="mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://orcid.org/0000-0002-9319-8559" title="ORCID" rel="external nofollow noopener" target="_blank"><i class="ai ai-orcid"></i></a> <a href="https://scholar.google.com/citations?user=14UikFkAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.researchgate.net/profile/Samuel-Huron/" title="ResearchGate" rel="external nofollow noopener" target="_blank"><i class="ai ai-researchgate"></i></a> <a href="https://dl.acm.org/profile/82258782457/" title="ACM DL" rel="external nofollow noopener" target="_blank"><i class="ai ai-acm"></i></a> <a href="https://www.linkedin.com/in/samuelhuron/" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/cybunk" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="https://youtube.com/@SamuelHuron" title="YouTube" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-youtube"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">You can even add a little note about which of these is the best way to reach you. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Samuel Huron. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-publications",title:"Publications",description:"Some of my latest publications by categories in reversed chronological order. generated by jekyll-scholar. To have a exhaustive list please consut my [Google scholar profile](https://scholar.google.com/citations?user=14UikFkAAAAJ&amp;hl=en&amp;oi=ao0.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-funding",title:"Funding",description:"Thanks to our funders that support our research.",section:"Navigation",handler:()=>{window.location.href="/funding/"}},{id:"nav-teaching",title:"Teaching",description:"This page is under construction. I plan to add my materials for courses you taught. Replace this text with your description.",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"nav-people",title:"People",description:"Phd Student and Post Doc I have supervised or I am supervising.",section:"Navigation",handler:()=>{window.location.href="/people/"}},{id:"nav-video",title:"Video",description:"different video presentation of research projects.",section:"Navigation",handler:()=>{window.location.href="/video/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"post-habiliation-\xe0-diriger-des-recherche-presentation",title:"Habiliation \xe0 Diriger Des Recherche - Presentation",description:"Habiliation a diriger des recherche - Presentation",section:"Posts",handler:()=>{window.location.href="/blog/2025/HDR-samuel-huron-supplemental/"}},{id:"post-hiring-an-assitant-associate-professor-in-design",title:"Hiring an Assitant Associate Professor In Design",description:"Hiring a new Assistant / Associate Professor in Design",section:"Posts",handler:()=>{window.location.href="/blog/2025/recrutement-prof-position/"}},{id:"post-recrutement-d-39-ing\xe9nieur-d-39-\xe9tude",title:"Recrutement d&#39;ing\xe9nieur d&#39;\xe9tude",description:"Recrutement Ing\xe9nieur d&#39;\xe9tude",section:"Posts",handler:()=>{window.location.href="/blog/2025/recrutement-ingenieur-recherche/"}},{id:"news-i-had-the-pleasure-to-be-interviewed-with-lora-oehlberg-in-the-andy-kirk-pod-cast-explore-explain-about-the-book-making-with-data",title:"I had the pleasure to be interviewed with Lora Oehlberg in the Andy...",description:"",section:"News"},{id:"news-i-was-in-hangzhou-china-for-graduation-ceremony-of-the-mast\xe8r-program-innovation-and-entreperneurship-at-zhejiang-university",title:"I was in Hangzhou (China) for graduation ceremony of the Mast\xe8r program Innovation...",description:"",section:"News"},{id:"news-i-attended-the-shonan-seminar-augmented-multimodal-interaction-for-synchronous-presentation-collaboration-and-education-with-remote-audiences-sparkles-smile",title:"I attended the Shonan Seminar Augmented Multimodal Interaction for Synchronous Presentation, Collaboration, and...",description:"",section:"News"},{id:"news-acm-conference-on-designing-interactive-systems-2024",title:"ACM Conference on Designing Interactive Systems 2024",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-elise-bonnail-and-wen-jie-tseng-successfully-defended-their-ph-d-elise-in-telecom-paris-the-3-of-may-and-wen-jie-in-darmstadt",title:"Elise Bonnail and Wen-Jie Tseng successfully defended their Ph.D. Elise In Telecom Paris...",description:"",section:"News"},{id:"news-i-will-be-part-of-the-panel-what-do-visualization-art-projects-bring-to-the-vis-community-wednesday-october-16th-from-8-30-am-to-9-45-am-edt-utc-4-at-ieee-vis",title:"I will be part of the panel ``What Do Visualization Art Projects Bring...",description:"",section:"News"},{id:"news-i-have-the-pleasure-to-co-organise-the-acm-iss-workshop-on-visual-methods-and-analyzing-visual-data-in-human-computer-interaction-the-workshop-will-take-place-in-vancouver-canada-but-remote-attendance-are-allowed-if-you-are-interested-join-us",title:"I have the pleasure to co-organise the ACM ISS workshop on Visual Methods...",description:"",section:"News"},{id:"news-the-9th-of-december-2024-we-will-organize-a-young-researcher-designer-s-day-on-theory-practice-and-politics-of-design-and-creative-action-at-\xe9coles-des-mines-in-paris-we-have-an-open-call-for-your-researcher-in-design-the-final-deadline-is-the-28-11-2024-here-is-the-call",title:"The 9th of December 2024 we will organize a Young Researcher/Designer\u2019s Day on...",description:"",section:"News"},{id:"news-between-the-01-11-to-07-11-i-was-at-ieee-vis-in-vienna-for-organizing-the-input-visualization-workshop-and-for-participating-to-the-panel-discussion-about-otto-neurath-words-divide-pictures-unite-revisiting-otto-neurath-s-isotype-at-100-also-anne-flore-cabouat-was-presenting-bridging-educational-theories-of-cognitive-load-to-visualization-design-and-evaluation-and-june-bhartia-was-presenting-exploring-touch-interactions-for-input-visualization-in-personal-informatics",title:"Between the 01/11 to 07/11, I was at IEEE VIS in Vienna, for...",description:"",section:"News"},{id:"news-i-succuesfull-defended-my-hdr-habiliation-\xe0-diriger-des-recherche-at-institut-polytechnique-de-paris-i-will-try-to-upload-the-document-and-slides-on-this-page-when-i-have-the-time-hdr-post",title:"I succuesfull defended my HDR (Habiliation \xe0 Diriger Des Recherche) at Institut Polytechnique...",description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0002-9319-8559","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=14UikFkAAAAJ","_blank")}},{id:"socials-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Samuel-Huron/","_blank")}},{id:"socials-acm-dl",title:"ACM DL",section:"Socials",handler:()=>{window.open("https://dl.acm.org/profile/82258782457/","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/samuelhuron/","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://twitter.com/cybunk","_blank")}},{id:"socials-youtube",title:"YouTube",section:"Socials",handler:()=>{window.open("https://youtube.com/@SamuelHuron","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>